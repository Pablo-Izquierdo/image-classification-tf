{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the saliency maps\n",
    "\n",
    "Once your classifier is trained you can visualize which pixels where the most relevant to estimate the volume of wine (or any other liquid) in an image. This is what we call the *saliency maps*.\n",
    "\n",
    "We will use the implementations of different saliency functions from the [deep-viz repository](https://github.com/experiencor/deep-viz-keras) by [experiencor](https://github.com/experiencor) which allows the visualization of saliency maps for keras models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from imgclas import paths, utils, data_utils\n",
    "from imgclas.data_utils import load_data_splits, k_crop_data_sequence\n",
    "from imgclas.test_utils import predict\n",
    "from imgclas.visualization.saliency import GradientSaliency\n",
    "from imgclas.visualization.guided_backprop import GuidedBackprop\n",
    "from imgclas.visualization.integrated_gradients import IntegratedGradients\n",
    "from imgclas.visualization.visual_backprop import VisualBackprop\n",
    "\n",
    "# User parameters to set\n",
    "TIMESTAMP = '2024-05-14_074436'                       # timestamp of the model\n",
    "FOLD = \"Fold-2\"                                        # Fold of CV to use, set to \"\" if not use CV\n",
    "MODEL_NAME = 'final_model.h5'                            # model to use to make the prediction\n",
    "SPLIT_NAME='test'                                       # Split data used\n",
    "TOP_K = 2                                               # number of top classes predictions to save\n",
    "\n",
    "# Set the timestamp\n",
    "paths.timestamp = TIMESTAMP\n",
    "\n",
    "# Load training configuration\n",
    "conf_path = os.path.join(paths.get_conf_dir(), 'conf.json')\n",
    "with open(conf_path) as f:\n",
    "    conf = json.load(f)\n",
    "\n",
    "if FOLD == \"\":\n",
    "    filepath = os.path.join(paths.get_checkpoints_dir(), MODEL_NAME)\n",
    "else:\n",
    "    filepath = os.path.join(paths.get_checkpoints_dir()+\"/\"+FOLD, MODEL_NAME)\n",
    "    \n",
    "obj=utils.get_custom_objects()\n",
    "\n",
    "# Load the model\n",
    "model = load_model(filepath, custom_objects=obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can select a file in your computer in which to visualize the saliency maps. \n",
    "Possible visualizations include:\n",
    "* [Vanila gradient](https://arxiv.org/abs/1312.6034)\n",
    "* [Integrated gradients](https://arxiv.org/abs/1703.01365)\n",
    "\n",
    "Each of them is accompanied with the corresponding [smoothgrad](https://arxiv.org/abs/1706.03825) version, which improves on any baseline method by adding random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "if FOLD == \"\":\n",
    "    pred_path = os.path.join(paths.get_predictions_dir(), '{}+{}.json'.format(MODEL_NAME, SPLIT_NAME, TOP_K))\n",
    "else:\n",
    "    pred_path = os.path.join(paths.get_predictions_dir()+\"/\"+FOLD, '{}+{}.json'.format(MODEL_NAME, SPLIT_NAME, TOP_K))\n",
    "    \n",
    "with open(pred_path) as f:\n",
    "    prediccion_data = json.load(f)\n",
    "    \n",
    "prediccion_df = pd.DataFrame.from_dict(prediccion_data)\n",
    "prediccion_df['abs_error'] = abs(prediccion_df.pred_value-prediccion_df.true_value)\n",
    "prediccion_df = prediccion_df.sort_values(by=['abs_error'])\n",
    "prediccion_df.columns=['filepath', 'pred_value', 'true_value', 'abs_error']\n",
    "prediccion_df['filenames']=prediccion_df.apply(lambda row: row.filepath[0:-4].split('/')[-1], axis=1) #Separamos por barraBaja, quitando .JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = prediccion_df.head(10)\n",
    "worst_pred = prediccion_df.tail(10).sort_values(by=['abs_error'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_saliency(FILEPATH, FILENAME, pred_value, true_value, TYPE):\n",
    "    saliency_types = [GradientSaliency, IntegratedGradients]\n",
    "\n",
    "    figsize = 5\n",
    "    fig, axs = plt.subplots(2, len(saliency_types)+1, figsize=(figsize*(len(saliency_types)+1), figsize*2))\n",
    "    top_title = \"Peso Original: \"+str(true_value)+\"\\nPeso Predicho: \"+str(pred_value)\n",
    "    fig.suptitle(top_title, fontsize=24, y=1.05) #Titulo General TODO: Probar...\n",
    "    gs = axs[0, 0].get_gridspec()\n",
    "    # remove the underlying axes\n",
    "    for ax in axs[0:, 0]:\n",
    "        ax.remove()\n",
    "    axbig = fig.add_subplot(gs[0:, 0])\n",
    "\n",
    "    # Load the image and preprocess it for the saliency maps computation\n",
    "    data_gen = k_crop_data_sequence(inputs=[FILEPATH],\n",
    "                                    im_size=conf['model']['image_size'],\n",
    "                                    mean_RGB=conf['dataset']['mean_RGB'],\n",
    "                                    std_RGB=conf['dataset']['std_RGB'],\n",
    "                                    preprocess_mode=conf['model']['preprocess_mode'],\n",
    "                                    aug_params=None,\n",
    "                                    crop_mode='random',\n",
    "                                    crop_number=1)\n",
    "\n",
    "    img_arr = data_gen.__getitem__(0)\n",
    "    img_arr = img_arr.squeeze(axis=0)\n",
    "\n",
    "    # Original image\n",
    "    image = data_utils.load_image(FILEPATH)#\n",
    "    image = data_utils.resize_im(image, height=conf['model']['image_size'], width=conf['model']['image_size'])\n",
    "\n",
    "    axbig.imshow(image)\n",
    "    axbig.set_title('Original image', fontsize=32, pad=18)\n",
    "    axbig.set_xticks([])\n",
    "    axbig.set_yticks([])\n",
    "    axbig.xaxis.set_visible(False)\n",
    "    axbig.yaxis.set_visible(False)\n",
    "    axs = axs.T.flatten()\n",
    "    # fig.delaxes(axs[1])\n",
    "    axs = axs[2:]\n",
    "\n",
    "    # Saliency maps\n",
    "    # right\n",
    "    axs[2].set_ylabel('Standard', fontsize=31,rotation=270, labelpad=31)\n",
    "    axs[3].set_ylabel('Smoothed', fontsize=31,rotation=270, labelpad=31)\n",
    "    # left\n",
    "    # axs[0].set_ylabel('Standard', fontsize=12)\n",
    "    # axs[1].set_ylabel('Smoothed', fontsize=12)\n",
    "    for i, f in enumerate(saliency_types):\n",
    "        print('[{}/{}] {}'.format(i+1, len(saliency_types), f.__name__))\n",
    "        saliency_func = f(model)\n",
    "\n",
    "        # Normal map\n",
    "        mask = saliency_func.get_mask(img_arr)\n",
    "        mask = np.sum(np.abs(mask), axis=2)\n",
    "        axs[i*2].imshow(mask, cmap=plt.cm.gray, vmin=np.amin(mask), vmax=np.percentile(mask, 98))\n",
    "        axs[i*2].set_title(saliency_func.__class__.__name__, fontsize=32, pad=18)\n",
    "\n",
    "        # Smoothgrad map\n",
    "        mask = saliency_func.get_smoothed_mask(img_arr)\n",
    "        mask = np.sum(np.abs(mask), axis=2)\n",
    "        axs[i*2+1].imshow(mask, cmap=plt.cm.gray, vmin=np.amin(mask), vmax=np.percentile(mask, 98))\n",
    "\n",
    "    # remove the x and y ticks\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.yaxis.set_label_position(\"right\")\n",
    "\n",
    "    fig.tight_layout(pad=1.0)\n",
    "    result_path = '/srv/image-results/saliencyMaps/'+TYPE+'/'+FILENAME\n",
    "    plt.savefig(result_path,bbox_inches='tight')\n",
    "    # Print predicted labels\n",
    "    #pred_value = predict(model, FILEPATH, conf)\n",
    "    #print('Predicted value:')\n",
    "    #print('{}'.format(pred_value[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"/srv/image-results\"):\n",
    "    os.mkdir(\"/srv/image-results\")\n",
    "if not os.path.exists(\"/srv/image-results/saliencyMaps\"):\n",
    "    os.mkdir(\"/srv/image-results/saliencyMaps\")\n",
    "if not os.path.exists(\"/srv/image-results/saliencyMaps/best\"):\n",
    "    os.mkdir(\"/srv/image-results/saliencyMaps/best\")\n",
    "if not os.path.exists(\"/srv/image-results/saliencyMaps/worst\"):\n",
    "    os.mkdir(\"/srv/image-results/saliencyMaps/worst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath,filename, pred_value, true_value in zip(best_pred['filepath'],best_pred['filenames'],best_pred['pred_value'],best_pred['true_value']) :\n",
    "    #print(filepath,filename, pred_value, true_value)\n",
    "    # Generate_saliency\n",
    "    pred_value = float(\"{:.2f}\".format(pred_value))\n",
    "    true_value = float(\"{:.2f}\".format(true_value))\n",
    "    generate_saliency(filepath, filename, pred_value, true_value, \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worst predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(worst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worst predictions\n",
    "for filepath,filename, pred_value, true_value in zip(worst_pred['filepath'],worst_pred['filenames'],worst_pred['pred_value'],worst_pred['true_value']) :\n",
    "    #print(filepath,filename, pred_value, true_value)\n",
    "    # Generate_saliency\n",
    "    pred_value = float(\"{:.2f}\".format(pred_value))\n",
    "    true_value = float(\"{:.2f}\".format(true_value))\n",
    "    generate_saliency(filepath, filename, pred_value, true_value, \"worst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
