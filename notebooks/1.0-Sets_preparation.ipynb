{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide your data into train, val and test sets\n",
    "\n",
    "Select the file *.txt* that contains all the images and its corresponding classes. Now we want to split our images into training, validation and testing files, so that the different volume classes are well distributed (e.g. if the dataset is highly imbalanced the images are not randomly separated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import os\n",
    "import hashlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "\n",
    "from collections import Counter\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para separar en bins\n",
    "def get_bin(true_values):\n",
    "    \n",
    "    grams = [100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375]\n",
    "    bins = [87.5, 112.5, 137.5, 162.5, 187.5, 212.5, 237.5, 262.5, 287.5, 312.5, 337.5, 362.5, 387.5]\n",
    "    \n",
    "    \n",
    "    if type(true_values) == list:\n",
    "        result = list()\n",
    "        for e in true_values:\n",
    "            l = len(bins)\n",
    "            index = 0\n",
    "            for i in range(l):\n",
    "                try:\n",
    "                    if bins[i] < float(e) and bins[i+1] > float(e):\n",
    "                        index = i\n",
    "                        result.append(grams[index])\n",
    "                        break\n",
    "                except:\n",
    "                    print(\"Error:\", e)\n",
    "    else:\n",
    "        l = len(bins)\n",
    "        index = 0\n",
    "        for i in range(l):\n",
    "            try:\n",
    "                if bins[i] < float(true_values) and bins[i+1] > float(true_values):\n",
    "                    index = i\n",
    "                    result = grams[index]\n",
    "                    break\n",
    "            except:\n",
    "                print(\"Error:\", true_values)\n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funcion que genera el chisero dataset.txt con las carpetas de imagenes y un dataframe con path y bin_size\n",
    "def generate_dataset_file(fruitDirectory):\n",
    "\n",
    "    # VALUES(date, user, picture, hash, location, idfruta, idvariedad, tamaño, luz, plano, angulo, plato, superficie);\n",
    "    with open('../data/dataset_files/dataset.txt', 'w') as fw: #Escribo en fichero dataset\n",
    "        df = pd.DataFrame(columns=['path', 'clase'])\n",
    "        for variety in os.listdir(fruitDirectory): # Para cada variedad\n",
    "            varietyDirectory = fruitDirectory + variety + \"/\"\n",
    "            print(varietyDirectory)\n",
    "            variety = varietyDirectory.split(\"/\")[3]\n",
    "            for sizeDirectory in os.listdir(varietyDirectory): # Para cada peso\n",
    "                tamaño=sizeDirectory\n",
    "                sizeDirectory = varietyDirectory + sizeDirectory + \"/\"\n",
    "\n",
    "                df = df.append(pd.DataFrame([[sizeDirectory,float(get_bin(tamaño.replace(\",\",\".\"))),variety]],\n",
    "                                            columns=['path', 'clase', 'variety']), ignore_index=True)\n",
    "        \n",
    "                string = str(sizeDirectory) + '*' + str(tamaño.replace(\",\",\".\"))+'\\n'\n",
    "                fw.write(string)\n",
    "                \n",
    "    fw.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribo en el fichero el path y tamaño extraido del path\n",
    "def write_file(writefile, X):\n",
    "    \n",
    "    print(\"Writing \"+ writefile)\n",
    "    with open('../data/dataset_files/'+writefile, 'w') as fw: #Escribo en fichero Train\n",
    "        for i in range(len(X)):\n",
    "            directory= X.iloc[i]\n",
    "            tamaño = directory.split('/')[-2].replace(',','.')\n",
    "            for filename in os.listdir(directory+\"/\"): \n",
    "                #print(filename)\n",
    "                f = os.path.join(directory, filename)\n",
    "                #checking if it is a file\n",
    "                if not os.path.isfile(f):\n",
    "                    raise Exception(\"File Not found: \" + str(f))\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    _ = io.imread(f)\n",
    "                    string = str(f) + '*' + str(tamaño)+'\\n'\n",
    "                    fw.write(string)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f)\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/MANZANA/Fuji/\n",
      "/storage/MANZANA/Golden/\n",
      "/storage/MANZANA/Granny Smith/\n",
      "                                      path  clase       variety\n",
      "0            /storage/MANZANA/Fuji/108.63/  125.0          Fuji\n",
      "1            /storage/MANZANA/Fuji/109.11/  125.0          Fuji\n",
      "2            /storage/MANZANA/Fuji/129.11/  125.0          Fuji\n",
      "3            /storage/MANZANA/Fuji/129.84/  125.0          Fuji\n",
      "4            /storage/MANZANA/Fuji/131.07/  125.0          Fuji\n",
      "..                                     ...    ...           ...\n",
      "172  /storage/MANZANA/Granny Smith/270,41/  275.0  Granny Smith\n",
      "173  /storage/MANZANA/Granny Smith/272,28/  275.0  Granny Smith\n",
      "174  /storage/MANZANA/Granny Smith/276,01/  275.0  Granny Smith\n",
      "175  /storage/MANZANA/Granny Smith/283,04/  275.0  Granny Smith\n",
      "176  /storage/MANZANA/Granny Smith/295,00/  300.0  Granny Smith\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "Train: Counter({200.0: 30, 250.0: 19, 150.0: 18, 225.0: 15, 125.0: 12, 275.0: 12, 175.0: 12, 300.0: 5})\n",
      "Test: Counter({200.0: 9, 250.0: 6, 150.0: 5, 175.0: 4, 225.0: 4, 125.0: 4, 275.0: 3, 300.0: 1})\n",
      "Val: Counter({200.0: 4, 250.0: 3, 150.0: 3, 175.0: 2, 275.0: 2, 225.0: 2, 300.0: 1, 125.0: 1})\n",
      "Writing train.txt\n",
      "Writing val.txt\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Pgb_ext_al_ver.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Ppb_ext_al_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spb_ext_al_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spb_ext_al_sup.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spb_ext_me_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spm_ext_al_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spm_ext_al_ver.JPG\n",
      "/storage/MANZANA/Granny Smith/171,74/Mad_M_Granny Smith_171,74_Spm_ext_me_cen.JPG\n",
      "Writing test.txt\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Pgb_ext_al_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Pgb_ext_ce_sup.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Pgb_ext_me_sup.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Pgb_ext_me_ver.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Ppb_ext_ce_ver.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Ppb_ext_me_cen.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Spm_ext_al_sup.JPG\n",
      "/storage/MANZANA/Granny Smith/235,42/Mad_M_Granny Smith_235,42_Spm_ext_al_ver.JPG\n"
     ]
    }
   ],
   "source": [
    "# Estratificamos datos y escribimos en fichero\n",
    "def gen_data(dataset_dir):\n",
    "\n",
    "    #Genero dataset.txt y obtengo df [path, size]\n",
    "    df = generate_dataset_file(dataset_dir)\n",
    "    #df = df.sort_values(by=['clase'])\n",
    "    for i in range(len(df.clase)): #Hay pocas manzanas superiores a 300g por lo que se combinan dentro del bin 300g\n",
    "        if df.clase[i] > 300:\n",
    "            df.clase[i] = 300\n",
    "        elif df.clase[i] < 125:\n",
    "            df.clase[i] = 125\n",
    "    #Dristribuir en train, test, val\n",
    "    print(df)\n",
    "    X_train, X_2, y_train, y_2 = train_test_split(df.path, df.clase, test_size=0.30, random_state=1, stratify=df.clase)\n",
    "    print(\"Train:\", Counter(y_train))\n",
    "\n",
    "    #print(Counter(y_2))\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_2, y_2, test_size=0.33, random_state=1, stratify=y_2)\n",
    "    print(\"Test:\",Counter(y_test))\n",
    "    print(\"Val:\",Counter(y_val))\n",
    "    #Train\n",
    "    write_file('train.txt', X_train)\n",
    "    #val\n",
    "    write_file('val.txt', X_val)\n",
    "    #Test\n",
    "    write_file('test.txt', X_test)\n",
    "    \n",
    "gen_data('/storage/MANZANA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "#Escribo en el fichero el path y tamaño extraido del path\n",
    "def write_file_df(writefile, df):\n",
    "   \n",
    "    # ESCRIBIR EN FICHERO\n",
    "    print(\"Writing \"+ writefile)\n",
    "    with open('../data/dataset_files/'+writefile, 'w') as fw: #Escribo en fichero Train\n",
    "        for i in range(len(df.path)):\n",
    "            directory= df.path.iloc[i]\n",
    "            tamaño = directory.split('/')[-2].replace(',','.')\n",
    "\n",
    "            #print(directory, tamaño)\n",
    "            for filename in os.listdir(directory+\"/\"): \n",
    "                #print(filename)\n",
    "                f = os.path.join(directory, filename)\n",
    "                #checking if it is a file\n",
    "                if not os.path.isfile(f):\n",
    "                    raise Exception(\"File Not found: \" + str(f))\n",
    "\n",
    "                try:\n",
    "\n",
    "                    _ = io.imread(f)\n",
    "                    string = str(f) + '*' + str(tamaño)+'\\n'\n",
    "                    fw.write(string)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f)\n",
    "\n",
    "        fw.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df):\n",
    "     # Obtendo la clase mas representada (Peso más representado)\n",
    "    class_most_common_name = Counter(df.clase).most_common()[0][0]\n",
    "    class_most_common_value = Counter(df.clase).most_common()[0][1]\n",
    "    \n",
    "    # Como esa clase puede estar desbalanceada (por variedad), obtengo la frecuencia de la variedad más representada.\n",
    "    freq_variety_top = Counter(df.loc[df.clase == class_most_common_name].variety).most_common()[0][1]\n",
    "    #print(\"freq_variety_top\",freq_variety_top)\n",
    "    # El numero de carpetas por clase sera freq_variety_top x 3variedades\n",
    "    total_freq_for_balanced_class = freq_variety_top * 3\n",
    "    \n",
    "    # Creo una copia del df, donde añadiré carpetas repetidas, con el objetivo de balancear las clases.\n",
    "    df_repetidas = df.copy()\n",
    "    #print(\"df_repetidas:\\n\", df_repetidas)\n",
    "    \n",
    "    #TODO: seria añadir lineas con carpetas repetidas antes de empezar a escribir. Y despues escribir\n",
    "    #Para cada clase (que cuenta con ciertas carpetas), repito carpetas hasta llegar al total_freq_for_balanced_class\n",
    "    for clase, lenght in Counter(df.clase).most_common(): #Para clase\n",
    "        repetir_rand = total_freq_for_balanced_class - lenght\n",
    "        print(\"###Clase: \",clase,\"###\")\n",
    "        print(\"lenght:\", lenght, \"rand:\",repetir_rand)\n",
    "        print(\"DF INICIAL: \",Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "        #print(Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "        for j in range(repetir_rand): #TODO: EJECUTA RARO\n",
    "            ## TODO: Se necesita ejecutar tantas veces como repeticiones necesarias\n",
    "            # En cada ejecucion se mira la variedad menos representada y se selecciona aleatoriamente\n",
    "            #una carpeta de esta manzana, se añade al df y se repite proceso\n",
    "\n",
    "            # Miramos la variedad menos representada, teniendo en cuenta las repeticiones\n",
    "            less_common_variety = Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common()[-1][0]\n",
    "            \n",
    "            # Obtenemos la lista con las frutas a repetir, sin las repeticiones ya añadidas\n",
    "            df_less_common = df[(df.clase == clase) & (df.variety == str(less_common_variety))].path.tolist()\n",
    "            \n",
    "            # Seleccioamos aleatoriamente una manzana para repetir todas sus imagenes\n",
    "            choosen = rand.choice(df_less_common)\n",
    "            row = {'path': choosen, 'clase': clase, 'variety': less_common_variety}\n",
    "            df_repetidas=df_repetidas.append(row, ignore_index=True) #TODO: HAY QUE AÑADIR AL DF_REPETIDAS LA ELEGIDA. REPETIR\n",
    "            #print(\"repetidas:\\n\", df_repetidas)\n",
    "            #print(less_common_variety\n",
    "            #rand.sample(df.path, k=repetir_rand) # TODO: RANDOM?? tener en cuenta la variedad\n",
    "        \n",
    "        print(\"DF RESULTADO: \",Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "        print(\"TAMAÑO FINAL: \",total_freq_for_balanced_class)\n",
    "        print(\"###########\")\n",
    "        \n",
    "    print(\"tamaño df_repetidas:\", len(df_repetidas))\n",
    "    print(Counter(df_repetidas.clase).most_common())\n",
    "    print(Counter(df_repetidas.variety).most_common())\n",
    "    print(df_repetidas)\n",
    "    \n",
    "    return df_repetidas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/MANZANA/Fuji/\n",
      "/storage/MANZANA/Golden/\n",
      "/storage/MANZANA/Granny Smith/\n",
      "                                      path  clase       variety\n",
      "0            /storage/MANZANA/Fuji/108.63/  125.0          Fuji\n",
      "1            /storage/MANZANA/Fuji/109.11/  125.0          Fuji\n",
      "2            /storage/MANZANA/Fuji/129.11/  125.0          Fuji\n",
      "3            /storage/MANZANA/Fuji/129.84/  125.0          Fuji\n",
      "4            /storage/MANZANA/Fuji/131.07/  125.0          Fuji\n",
      "..                                     ...    ...           ...\n",
      "173  /storage/MANZANA/Granny Smith/270,41/  275.0  Granny Smith\n",
      "174  /storage/MANZANA/Granny Smith/272,28/  275.0  Granny Smith\n",
      "175  /storage/MANZANA/Granny Smith/276,01/  275.0  Granny Smith\n",
      "176  /storage/MANZANA/Granny Smith/283,04/  275.0  Granny Smith\n",
      "177  /storage/MANZANA/Granny Smith/295,00/  300.0  Granny Smith\n",
      "\n",
      "[178 rows x 3 columns]\n",
      "Train: Counter({200.0: 30, 250.0: 19, 150.0: 18, 225.0: 16, 175.0: 12, 125.0: 12, 275.0: 12, 300.0: 5})\n",
      "124    /storage/MANZANA/Granny Smith/173,76/\n",
      "162    /storage/MANZANA/Granny Smith/234,79/\n",
      "9              /storage/MANZANA/Fuji/136.37/\n",
      "52             /storage/MANZANA/Fuji/286.43/\n",
      "168    /storage/MANZANA/Granny Smith/243,74/\n",
      "40             /storage/MANZANA/Fuji/248.73/\n",
      "148    /storage/MANZANA/Granny Smith/214,21/\n",
      "68           /storage/MANZANA/Golden/139.04/\n",
      "117          /storage/MANZANA/Golden/258.65/\n",
      "145    /storage/MANZANA/Granny Smith/209,01/\n",
      "77           /storage/MANZANA/Golden/152.55/\n",
      "129    /storage/MANZANA/Granny Smith/183,96/\n",
      "99           /storage/MANZANA/Golden/212,54/\n",
      "97           /storage/MANZANA/Golden/204,04/\n",
      "24             /storage/MANZANA/Fuji/198.80/\n",
      "113          /storage/MANZANA/Golden/251.28/\n",
      "59             /storage/MANZANA/Fuji/320.09/\n",
      "169    /storage/MANZANA/Granny Smith/245,22/\n",
      "67           /storage/MANZANA/Golden/138.45/\n",
      "15             /storage/MANZANA/Fuji/145.59/\n",
      "61           /storage/MANZANA/Golden/127.00/\n",
      "47             /storage/MANZANA/Fuji/273.78/\n",
      "46             /storage/MANZANA/Fuji/271.68/\n",
      "8              /storage/MANZANA/Fuji/135.44/\n",
      "94           /storage/MANZANA/Golden/196,68/\n",
      "89           /storage/MANZANA/Golden/188.92/\n",
      "88           /storage/MANZANA/Golden/186.88/\n",
      "28             /storage/MANZANA/Fuji/202.21/\n",
      "140    /storage/MANZANA/Granny Smith/201,67/\n",
      "96           /storage/MANZANA/Golden/202,84/\n",
      "138    /storage/MANZANA/Granny Smith/200,47/\n",
      "153    /storage/MANZANA/Granny Smith/221,80/\n",
      "83           /storage/MANZANA/Golden/179.79/\n",
      "155    /storage/MANZANA/Granny Smith/222,37/\n",
      "121    /storage/MANZANA/Granny Smith/154,97/\n",
      "66           /storage/MANZANA/Golden/137.12/\n",
      "Name: path, dtype: object\n",
      "###Clase:  200.0 ###\n",
      "lenght: 30 rand: 6\n",
      "DF INICIAL:  [('Granny Smith', 12), ('Fuji', 12), ('Golden', 6)]\n",
      "DF RESULTADO:  [('Granny Smith', 12), ('Fuji', 12), ('Golden', 12)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  250.0 ###\n",
      "lenght: 19 rand: 17\n",
      "DF INICIAL:  [('Golden', 14), ('Granny Smith', 4), ('Fuji', 1)]\n",
      "DF RESULTADO:  [('Golden', 14), ('Granny Smith', 11), ('Fuji', 11)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  150.0 ###\n",
      "lenght: 18 rand: 18\n",
      "DF INICIAL:  [('Fuji', 8), ('Golden', 8), ('Granny Smith', 2)]\n",
      "DF RESULTADO:  [('Fuji', 12), ('Golden', 12), ('Granny Smith', 12)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  225.0 ###\n",
      "lenght: 16 rand: 20\n",
      "DF INICIAL:  [('Granny Smith', 12), ('Golden', 2), ('Fuji', 2)]\n",
      "DF RESULTADO:  [('Granny Smith', 12), ('Golden', 12), ('Fuji', 12)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  175.0 ###\n",
      "lenght: 12 rand: 24\n",
      "DF INICIAL:  [('Golden', 6), ('Granny Smith', 6)]\n",
      "DF RESULTADO:  [('Golden', 18), ('Granny Smith', 18)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  125.0 ###\n",
      "lenght: 12 rand: 24\n",
      "DF INICIAL:  [('Fuji', 8), ('Golden', 4)]\n",
      "DF RESULTADO:  [('Fuji', 18), ('Golden', 18)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  275.0 ###\n",
      "lenght: 12 rand: 24\n",
      "DF INICIAL:  [('Fuji', 8), ('Granny Smith', 4)]\n",
      "DF RESULTADO:  [('Fuji', 18), ('Granny Smith', 18)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "###Clase:  300.0 ###\n",
      "lenght: 5 rand: 31\n",
      "DF INICIAL:  [('Fuji', 4), ('Granny Smith', 1)]\n",
      "DF RESULTADO:  [('Fuji', 18), ('Granny Smith', 18)]\n",
      "TAMAÑO FINAL:  36\n",
      "###########\n",
      "tamaño df_repetidas: 288\n",
      "[(175.0, 36), (250.0, 36), (225.0, 36), (150.0, 36), (125.0, 36), (300.0, 36), (275.0, 36), (200.0, 36)]\n",
      "[('Granny Smith', 101), ('Fuji', 101), ('Golden', 86)]\n",
      "                                      path  clase       variety\n",
      "0          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "1          /storage/MANZANA/Golden/253.73/  250.0        Golden\n",
      "2          /storage/MANZANA/Golden/259.60/  250.0        Golden\n",
      "3    /storage/MANZANA/Granny Smith/236,92/  225.0  Granny Smith\n",
      "4            /storage/MANZANA/Fuji/143.54/  150.0          Fuji\n",
      "..                                     ...    ...           ...\n",
      "283          /storage/MANZANA/Fuji/307.11/  300.0          Fuji\n",
      "284  /storage/MANZANA/Granny Smith/295,00/  300.0  Granny Smith\n",
      "285          /storage/MANZANA/Fuji/306.67/  300.0          Fuji\n",
      "286  /storage/MANZANA/Granny Smith/295,00/  300.0  Granny Smith\n",
      "287          /storage/MANZANA/Fuji/307.11/  300.0          Fuji\n",
      "\n",
      "[288 rows x 3 columns]\n",
      "Writing train.txt\n"
     ]
    }
   ],
   "source": [
    "# Estratificamos datos y escribimos en fichero\n",
    "def gen_data(dataset_dir):\n",
    "\n",
    "    #Genero dataset.txt y obtengo df [path, size]\n",
    "    df = generate_dataset_file(dataset_dir)\n",
    "    #df = df.sort_values(by=['clase'])\n",
    "    for i in range(len(df.clase)): #Hay pocas manzanas superiores a 300g por lo que se combinan dentro del bin 300g\n",
    "        if df.clase[i] > 300:\n",
    "            df.clase[i] = 300\n",
    "        elif df.clase[i] < 125:\n",
    "            df.clase[i] = 125\n",
    "    #Dristribuir en train, test, val\n",
    "    print(df)\n",
    "    X_train, X_2, y_train, y_2 = train_test_split(df.path, df.clase, test_size=0.30, random_state=1, stratify=df.clase)\n",
    "    print(\"Train:\", Counter(y_train))\n",
    "    df_train = df.loc[X_train.index]\n",
    "\n",
    "    #print(Counter(y_2))\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_2, y_2, test_size=0.33, random_state=1, stratify=y_2)\n",
    "    print(X_test)\n",
    "    df_test = df.loc[X_test.index]\n",
    "    df_val = df.loc[X_val.index]\n",
    "   # print(\"Test:\",Counter(y_test))\n",
    "   # print(\"Val:\",Counter(y_val))\n",
    "    #Train\n",
    "    write_file_df('train.txt',balance_df(df_train))\n",
    "    #val\n",
    "    #write_file('val.txt', X_val)\n",
    "    #Test\n",
    "    #write_file('test.txt', X_test)\n",
    "    \n",
    "gen_data('/storage/MANZANA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide your data into train, test sets for CrossValidation\n",
    "\n",
    "Objetivo: Crear una funcion que generé los ficheros Train.txt/test.txt para cada fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_label_variety(splits_dir, im_dir, split_name='dataset'):\n",
    "    \"\"\"\n",
    "    Load the data arrays from the [train/val/test].txt files.\n",
    "    Lines of txt files have the following format:\n",
    "    'absolute_path_to_image'*'image_label_number_in_mL'\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im_dir : str\n",
    "        Absolute path to the image folder.\n",
    "    split_name : str\n",
    "        Name of the data split to load\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : Numpy array of strs\n",
    "        First colunm: Contains 'absolute_path_to_file' to images.\n",
    "    y : Numpy array of int32\n",
    "        Image label number\n",
    "    \"\"\"\n",
    "    if '{}.txt'.format(split_name) not in os.listdir(splits_dir):\n",
    "        raise ValueError(\"Invalid value for the split_name parameter: there is no `{}.txt` file in the `{}` \"\n",
    "                         \"directory.\".format(split_name, splits_dir))\n",
    "\n",
    "    # Loading splits\n",
    "    print(\"Loading {} data...\".format(split_name))\n",
    "    split = np.genfromtxt(os.path.join(splits_dir, '{}.txt'.format(split_name)), dtype='str', delimiter='*') ### previously: delimiter=' '\n",
    "    X = np.array([os.path.join(im_dir, i) for i in split[:, 0]])\n",
    "    v = np.array([i.split(\"/\")[3] for i in split[:, 0]])\n",
    "    \n",
    "    # Leer Peso\n",
    "    if len(split.shape) == 2:\n",
    "        y = split[:, 1].astype(np.float32)\n",
    "    else: # maybe test file has not labels\n",
    "        y = None\n",
    "        \n",
    "\n",
    "        \n",
    "    return X, y, v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribo en el fichero el path y tamaño extraido del path\n",
    "def write_file(writefile, X):\n",
    "    \n",
    "    print(\"Writing \"+ writefile)\n",
    "    with open('../data/dataset_files/'+writefile, 'w') as fw: #Escribo en fichero Train\n",
    "        for i in range(len(X)):\n",
    "            directory= X[i]\n",
    "            tamaño = directory.split('/')[-2].replace(',','.')\n",
    "            for filename in os.listdir(directory): \n",
    "                #print(filename)\n",
    "                f = os.path.join(directory, filename)\n",
    "                #checking if it is a file\n",
    "                if not os.path.isfile(f):\n",
    "                    raise Exception(\"File Not found: \" + str(f))\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    _ = io.imread(f)\n",
    "                    string = str(f) + '*' + str(tamaño)+'\\n'\n",
    "                    fw.write(string)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f)\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset data...\n",
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "########Fold-0#########\n",
      "Directory Exists\n",
      "Writing Fold-0/train.txt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-a05eae974a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m#print(f\"  Test:  index={test_index}, data={y[test_index]}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mgen_data_CV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-84-a05eae974a49>\u001b[0m in \u001b[0;36mgen_data_CV\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Escribo datos Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{fold}/train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Escribo datos Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-83-b5848303812a>\u001b[0m in \u001b[0;36mwrite_file\u001b[0;34m(writefile, X)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                     \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtamaño\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mfw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m                                (plugin, kind))\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mimopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ri\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/legacy_plugin_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlegacy_get_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_BaseReaderWriter_last_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow_legacy.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m             \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPillowFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0;31m# Handle exif\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow_legacy.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    343\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawmode_saved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_get_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow_legacy.py\u001b[0m in \u001b[0;36mpil_get_frame\u001b[0;34m(im, is_gray, as_gray, mode, dtype)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"PNG\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"I\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"uint16\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m             \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mArrayData\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imgclas import paths\n",
    "import os\n",
    "\n",
    "\n",
    "def gen_data_CV():\n",
    "    X, y, v= read_file_label_variety(splits_dir=\"/srv/image-classification-tf/data/dataset_files\",\n",
    "                                            im_dir=paths.get_images_dir())\n",
    "\n",
    "    groups = v\n",
    "    Stratified_kfold = StratifiedKFold(n_splits=2)\n",
    "\n",
    "    Stratified_kfold.get_n_splits(X, groups)\n",
    "\n",
    "    print(group_kfold)\n",
    "    for i, (train_index, test_index) in enumerate(Stratified_kfold.split(X, groups)):\n",
    "        fold = f\"Fold-{i}\"\n",
    "        print(f'########{fold}#########')\n",
    "\n",
    "        try:\n",
    "            os.path.isdir(f\"/srv/image-classification-tf/data/dataset_files/{fold}\")\n",
    "            os.mkdir(f\"/srv/image-classification-tf/data/dataset_files/{fold}\")\n",
    "        except Exception as e:\n",
    "            print(\"Directory Exists\")\n",
    "        \n",
    "        \n",
    "        # Escribo datos Train\n",
    "        write_file(f'{fold}/train.txt', X[train_index].tolist())\n",
    "        \n",
    "        # Escribo datos Test\n",
    "        write_file(f'{fold}/train.txt', X[test_index].tolist())\n",
    "            \n",
    "            \n",
    "        print(train_index, test_index)\n",
    "        #print(f\"  Train: index={train_index}, data={X[train_index]}, y={y[train_index]}\")\n",
    "        #print(f\"  Test:  index={test_index}, data={y[test_index]}\")\n",
    "\n",
    "gen_data_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
