{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide your data into train, val and test sets\n",
    "\n",
    "Select the file *.txt* that contains all the images and its corresponding classes. Now we want to split our images into training, validation and testing files, so that the different volume classes are well distributed (e.g. if the dataset is highly imbalanced the images are not randomly separated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from enum import Enum\n",
    "from datetime import datetime\n",
    "import os\n",
    "import hashlib\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "\n",
    "from collections import Counter\n",
    "import random as r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcion para separar en bins\n",
    "def get_bin(true_values):\n",
    "    \n",
    "    grams = [100, 125, 150, 175, 200, 225, 250, 275, 300, 325, 350, 375]\n",
    "    bins = [87.5, 112.5, 137.5, 162.5, 187.5, 212.5, 237.5, 262.5, 287.5, 312.5, 337.5, 362.5, 387.5]\n",
    "    \n",
    "    \n",
    "    if type(true_values) == list:\n",
    "        result = list()\n",
    "        for e in true_values:\n",
    "            l = len(bins)\n",
    "            index = 0\n",
    "            for i in range(l):\n",
    "                try:\n",
    "                    if bins[i] < float(e) and bins[i+1] > float(e):\n",
    "                        index = i\n",
    "                        result.append(grams[index])\n",
    "                        break\n",
    "                except:\n",
    "                    print(\"Error:\", e)\n",
    "    else:\n",
    "        l = len(bins)\n",
    "        index = 0\n",
    "        for i in range(l):\n",
    "            try:\n",
    "                if bins[i] < float(true_values) and bins[i+1] > float(true_values):\n",
    "                    index = i\n",
    "                    result = grams[index]\n",
    "                    break\n",
    "            except:\n",
    "                print(\"Error:\", true_values)\n",
    "        \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funcion que genera el chisero dataset.txt con las carpetas de imagenes y un dataframe con path y bin_size\n",
    "def generate_dataset_file(fruitDirectory):\n",
    "\n",
    "    # VALUES(date, user, picture, hash, location, idfruta, idvariedad, tamaño, luz, plano, angulo, plato, superficie);\n",
    "    with open('../data/dataset_files/dataset.txt', 'w') as fw: #Escribo en fichero dataset\n",
    "        df = pd.DataFrame(columns=['path', 'clase'])\n",
    "        for variety in os.listdir(fruitDirectory): # Para cada variedad\n",
    "            varietyDirectory = fruitDirectory + variety + \"/\"\n",
    "            print(varietyDirectory)\n",
    "            variety = varietyDirectory.split(\"/\")[3]\n",
    "            for sizeDirectory in os.listdir(varietyDirectory): # Para cada peso\n",
    "                tamaño=sizeDirectory\n",
    "                sizeDirectory = varietyDirectory + sizeDirectory + \"/\"\n",
    "\n",
    "                df = df.append(pd.DataFrame([[sizeDirectory,float(get_bin(tamaño.replace(\",\",\".\"))),variety]],\n",
    "                                            columns=['path', 'clase', 'variety']), ignore_index=True)\n",
    "        \n",
    "                string = str(sizeDirectory) + '*' + str(tamaño.replace(\",\",\".\"))+'\\n'\n",
    "                fw.write(string)\n",
    "                \n",
    "    fw.close()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribo en el fichero el path y tamaño extraido del path\n",
    "def write_file(writefile, X):\n",
    "    \n",
    "    print(\"Writing \"+ writefile)\n",
    "    with open('../data/dataset_files/'+writefile, 'w') as fw: #Escribo en fichero Train\n",
    "        for i in range(len(X)):\n",
    "            directory= X.iloc[i]\n",
    "            tamaño = directory.split('/')[-2].replace(',','.')\n",
    "            #print(directory, tamaño)\n",
    "            for filename in os.listdir(directory+\"/\"): \n",
    "                #print(filename)\n",
    "                f = os.path.join(directory, filename)\n",
    "                #checking if it is a file\n",
    "                if not os.path.isfile(f):\n",
    "                    raise Exception(\"File Not found: \" + str(f))\n",
    "\n",
    "                try:\n",
    "                    '''\n",
    "                    _ = io.imread(f)\n",
    "                    string = str(f) + '*' + str(tamaño)+'\\n'\n",
    "                    fw.write(string)\n",
    "                    '''\n",
    "                except Exception as e:\n",
    "                    print(f)\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rand\n",
    "#Escribo en el fichero el path y tamaño extraido del path\n",
    "def write_file(writefile, df):\n",
    "    # Obtendo la clase mas representada\n",
    "    class_most_common = Counter(df.clase).most_common()[0][1]\n",
    "    \n",
    "    # Como esa clase puede estar desbalanceada (por variedad), obtengo la frecuencia de la variedad mas representada.\n",
    "    freq_variety_top = Counter(df.loc[df.clase == class_most_common].variety).most_common()[0][1]\n",
    "    \n",
    "    # El numero de carpetas por clase sera freq_variety_top x 3variedades\n",
    "    total_freq_for_balanced_class = freq_variety_top * 3\n",
    "    \n",
    "    # Creo una copia del df, donde añadiré carpetas repetidas, con el objetivo de balancear las clases.\n",
    "    df_repetidas = df.copy()\n",
    "    print(\"df_repetidas:\\n\", df_repetidas)\n",
    "    \n",
    "    #TODO: seria añadir lineas con carpetas repetidas antes de empezar a escribir. Y despues escribir\n",
    "    #Para cada clase (que cuenta con ciertas carpetas), repito carpetas hasta llegar al total_freq_for_balanced_class\n",
    "    for clase, lenght in Counter(df.clase).most_common(): #Para clase\n",
    "        repetir_rand = total_freq_for_balanced_class - lenght\n",
    "        print(clase)\n",
    "        print(\"lenght:\", lenght, \"rand:\",repetir_rand)\n",
    "        #if lenght < repetir_rand: #Necesario repetir\n",
    "        print(Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "        for j in range(repetir_rand): #TODO: EJECUTA RARO\n",
    "            ## TODO: Se necesita ejecutar tantas veces como repeticiones necesarias\n",
    "            # En cada ejecucion se mira la variedad menos representada y se selecciona aleatoriamente\n",
    "            #una carpeta de esta manzana, se añade al df y se repite proceso\n",
    "\n",
    "            #print(\"AHHH2\",j)\n",
    "            # Miramos la variedad menos representada, teniendo en cuenta las repeticiones\n",
    "            less_common_variety = Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common()[-1][0]\n",
    "            #print(Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "            # Obtenemos la lista con las frutas a repetir, sin las repeticiones ya añadidas\n",
    "            df_less_common = df[(df.clase == clase) & (df.variety == str(less_common_variety))].path.tolist()\n",
    "            #print(\"less_common_df:\", df_less_common)\n",
    "            choosen = rand.choice(df_less_common)\n",
    "            row = {'path': choosen, 'clase': clase, 'variety': less_common_variety}\n",
    "            df_repetidas=df_repetidas.append(row, ignore_index=True) #TODO: HAY QUE AÑADIR AL DF_REPETIDAS LA ELEGIDA. REPETIR\n",
    "            #print(\"repetidas:\\n\", df_repetidas)\n",
    "            #print(less_common_variety\n",
    "            #rand.sample(df.path, k=repetir_rand) # TODO: RANDOM?? tener en cuenta la variedad\n",
    "        print(Counter(df_repetidas.loc[df_repetidas.clase == clase].variety).most_common())\n",
    "        print(\"repetidas:\\n\", df_repetidas)\n",
    "        print(\"tamaño df:\", len(df_repetidas))\n",
    "\n",
    "       # elif lenght > repetir_rand and repetir_rand != 0: #Cada eleccion diferente\n",
    "       #     print(\"AAHH3\")\n",
    "            #rand.choices(range(0, len(df.path)), k=repetir_rand)\n",
    "\n",
    "        '''\n",
    "        # ESCRIBIR EN FICHERO\n",
    "        print(\"Writing \"+ writefile)\n",
    "        with open('../data/dataset_files/'+writefile, 'w') as fw: #Escribo en fichero Train\n",
    "            for i in range(len(df.path)):\n",
    "                directory= df.path.iloc[i]\n",
    "                tamaño = directory.split('/')[-2].replace(',','.')\n",
    "\n",
    "\n",
    "                #print(directory, tamaño)\n",
    "                for filename in os.listdir(directory+\"/\"): \n",
    "                    #print(filename)\n",
    "                    f = os.path.join(directory, filename)\n",
    "                    #checking if it is a file\n",
    "                    if not os.path.isfile(f):\n",
    "                        raise Exception(\"File Not found: \" + str(f))\n",
    "\n",
    "                    try:\n",
    "\n",
    "                        _ = io.imread(f)\n",
    "                        string = str(f) + '*' + str(tamaño)+'\\n'\n",
    "                        fw.write(string)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f)\n",
    "\n",
    "            fw.close()\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/MANZANA/Fuji/\n",
      "/storage/MANZANA/Golden/\n",
      "/storage/MANZANA/Granny Smith/\n",
      "                                      path  clase       variety\n",
      "0            /storage/MANZANA/Fuji/108.63/  125.0          Fuji\n",
      "1            /storage/MANZANA/Fuji/109.11/  125.0          Fuji\n",
      "2            /storage/MANZANA/Fuji/129.11/  125.0          Fuji\n",
      "3            /storage/MANZANA/Fuji/129.84/  125.0          Fuji\n",
      "4            /storage/MANZANA/Fuji/131.07/  125.0          Fuji\n",
      "..                                     ...    ...           ...\n",
      "138  /storage/MANZANA/Granny Smith/236,92/  225.0  Granny Smith\n",
      "139  /storage/MANZANA/Granny Smith/240,23/  250.0  Granny Smith\n",
      "140  /storage/MANZANA/Granny Smith/243,74/  250.0  Granny Smith\n",
      "141  /storage/MANZANA/Granny Smith/246,38/  250.0  Granny Smith\n",
      "142  /storage/MANZANA/Granny Smith/260,40/  250.0  Granny Smith\n",
      "\n",
      "[143 rows x 3 columns]\n",
      "Train: Counter({200.0: 22, 250.0: 17, 150.0: 17, 175.0: 13, 125.0: 12, 275.0: 8, 225.0: 7, 300.0: 4})\n",
      "22\n",
      "df_repetidas:\n",
      "                                       path  clase       variety\n",
      "118        /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "84         /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "46           /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "98         /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "136  /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "44           /storage/MANZANA/Fuji/268.98/  275.0          Fuji\n",
      "7            /storage/MANZANA/Fuji/134.15/  125.0          Fuji\n",
      "59           /storage/MANZANA/Fuji/320.09/  300.0          Fuji\n",
      "115        /storage/MANZANA/Golden/253.73/  250.0        Golden\n",
      "16           /storage/MANZANA/Fuji/146.54/  150.0          Fuji\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "200.0\n",
      "lenght: 22 rand: 0\n",
      "[('Fuji', 12), ('Golden', 7), ('Granny Smith', 3)]\n",
      "[('Fuji', 12), ('Golden', 7), ('Granny Smith', 3)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "118        /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "84         /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "46           /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "98         /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "136  /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "44           /storage/MANZANA/Fuji/268.98/  275.0          Fuji\n",
      "7            /storage/MANZANA/Fuji/134.15/  125.0          Fuji\n",
      "59           /storage/MANZANA/Fuji/320.09/  300.0          Fuji\n",
      "115        /storage/MANZANA/Golden/253.73/  250.0        Golden\n",
      "16           /storage/MANZANA/Fuji/146.54/  150.0          Fuji\n",
      "\n",
      "[100 rows x 3 columns]\n",
      "tamaño df: 100\n",
      "250.0\n",
      "lenght: 17 rand: 5\n",
      "[('Golden', 13), ('Fuji', 2), ('Granny Smith', 2)]\n",
      "[('Golden', 13), ('Granny Smith', 5), ('Fuji', 4)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "100  /storage/MANZANA/Granny Smith/260,40/  250.0  Granny Smith\n",
      "101          /storage/MANZANA/Fuji/248.73/  250.0          Fuji\n",
      "102  /storage/MANZANA/Granny Smith/243,74/  250.0  Granny Smith\n",
      "103          /storage/MANZANA/Fuji/253.17/  250.0          Fuji\n",
      "104  /storage/MANZANA/Granny Smith/243,74/  250.0  Granny Smith\n",
      "\n",
      "[105 rows x 3 columns]\n",
      "tamaño df: 105\n",
      "150.0\n",
      "lenght: 17 rand: 5\n",
      "[('Fuji', 8), ('Golden', 8), ('Granny Smith', 1)]\n",
      "[('Fuji', 8), ('Golden', 8), ('Granny Smith', 6)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "105  /storage/MANZANA/Granny Smith/154,97/  150.0  Granny Smith\n",
      "106  /storage/MANZANA/Granny Smith/154,97/  150.0  Granny Smith\n",
      "107  /storage/MANZANA/Granny Smith/154,97/  150.0  Granny Smith\n",
      "108  /storage/MANZANA/Granny Smith/154,97/  150.0  Granny Smith\n",
      "109  /storage/MANZANA/Granny Smith/154,97/  150.0  Granny Smith\n",
      "\n",
      "[110 rows x 3 columns]\n",
      "tamaño df: 110\n",
      "175.0\n",
      "lenght: 13 rand: 9\n",
      "[('Golden', 8), ('Granny Smith', 5)]\n",
      "[('Golden', 11), ('Granny Smith', 11)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "114        /storage/MANZANA/Golden/179.79/  175.0        Golden\n",
      "115  /storage/MANZANA/Granny Smith/174,65/  175.0  Granny Smith\n",
      "116        /storage/MANZANA/Golden/185.73/  175.0        Golden\n",
      "117  /storage/MANZANA/Granny Smith/174,65/  175.0  Granny Smith\n",
      "118        /storage/MANZANA/Golden/172.20/  175.0        Golden\n",
      "\n",
      "[119 rows x 3 columns]\n",
      "tamaño df: 119\n",
      "125.0\n",
      "lenght: 12 rand: 10\n",
      "[('Fuji', 7), ('Golden', 5)]\n",
      "[('Fuji', 11), ('Golden', 11)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "124          /storage/MANZANA/Fuji/134.15/  125.0          Fuji\n",
      "125        /storage/MANZANA/Golden/108.37/  125.0        Golden\n",
      "126          /storage/MANZANA/Fuji/108.63/  125.0          Fuji\n",
      "127        /storage/MANZANA/Golden/134.92/  125.0        Golden\n",
      "128          /storage/MANZANA/Fuji/108.63/  125.0          Fuji\n",
      "\n",
      "[129 rows x 3 columns]\n",
      "tamaño df: 129\n",
      "275.0\n",
      "lenght: 8 rand: 14\n",
      "[('Fuji', 8)]\n",
      "[('Fuji', 22)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "138          /storage/MANZANA/Fuji/287.19/  275.0          Fuji\n",
      "139          /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "140          /storage/MANZANA/Fuji/268.98/  275.0          Fuji\n",
      "141          /storage/MANZANA/Fuji/269.93/  275.0          Fuji\n",
      "142          /storage/MANZANA/Fuji/282.83/  275.0          Fuji\n",
      "\n",
      "[143 rows x 3 columns]\n",
      "tamaño df: 143\n",
      "225.0\n",
      "lenght: 7 rand: 15\n",
      "[('Granny Smith', 4), ('Golden', 2), ('Fuji', 1)]\n",
      "[('Fuji', 8), ('Granny Smith', 7), ('Golden', 7)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "153  /storage/MANZANA/Granny Smith/230,55/  225.0  Granny Smith\n",
      "154          /storage/MANZANA/Fuji/221.75/  225.0          Fuji\n",
      "155        /storage/MANZANA/Golden/237.44/  225.0        Golden\n",
      "156  /storage/MANZANA/Granny Smith/230,55/  225.0  Granny Smith\n",
      "157          /storage/MANZANA/Fuji/221.75/  225.0          Fuji\n",
      "\n",
      "[158 rows x 3 columns]\n",
      "tamaño df: 158\n",
      "300.0\n",
      "lenght: 4 rand: 18\n",
      "[('Fuji', 4)]\n",
      "[('Fuji', 22)]\n",
      "repetidas:\n",
      "                                       path  clase       variety\n",
      "0          /storage/MANZANA/Golden/259.08/  250.0        Golden\n",
      "1          /storage/MANZANA/Golden/180.51/  175.0        Golden\n",
      "2            /storage/MANZANA/Fuji/271.68/  275.0          Fuji\n",
      "3          /storage/MANZANA/Golden/207,98/  200.0        Golden\n",
      "4    /storage/MANZANA/Granny Smith/232,83/  225.0  Granny Smith\n",
      "..                                     ...    ...           ...\n",
      "171          /storage/MANZANA/Fuji/320.09/  300.0          Fuji\n",
      "172          /storage/MANZANA/Fuji/306.67/  300.0          Fuji\n",
      "173          /storage/MANZANA/Fuji/306.67/  300.0          Fuji\n",
      "174          /storage/MANZANA/Fuji/306.67/  300.0          Fuji\n",
      "175          /storage/MANZANA/Fuji/320.09/  300.0          Fuji\n",
      "\n",
      "[176 rows x 3 columns]\n",
      "tamaño df: 176\n"
     ]
    }
   ],
   "source": [
    "# Estratificamos datos y escribimos en fichero\n",
    "def gen_data(dataset_dir):\n",
    "\n",
    "    #Genero dataset.txt y obtengo df [path, size]\n",
    "    df = generate_dataset_file(dataset_dir)\n",
    "    #df = df.sort_values(by=['clase'])\n",
    "    for i in range(len(df.clase)): #Hay pocas manzanas superiores a 300g por lo que se combinan dentro del bin 300g\n",
    "        if df.clase[i] > 300:\n",
    "            df.clase[i] = 300\n",
    "        elif df.clase[i] < 125:\n",
    "            df.clase[i] = 125\n",
    "    #Dristribuir en train, test, val\n",
    "    print(df)\n",
    "    X_train, X_2, y_train, y_2 = train_test_split(df.path, df.clase, test_size=0.30, random_state=1, stratify=df.clase)\n",
    "    print(\"Train:\", Counter(y_train))\n",
    "    df_train = df.loc[X_train.index]\n",
    "\n",
    "    #print(Counter(y_2))\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_2, y_2, test_size=0.33, random_state=1, stratify=y_2)\n",
    "    df_test = df.loc[X_test.index]\n",
    "    df_val = df.loc[X_val.index]\n",
    "   # print(\"Test:\",Counter(y_test))\n",
    "   # print(\"Val:\",Counter(y_val))\n",
    "    most_common_weight = Counter(df_train.clase).most_common()[0][1]\n",
    "    print(most_common_weight)\n",
    "    #Train\n",
    "    write_file('train.txt', df_train)\n",
    "    #val\n",
    "    #write_file('val.txt', X_val)\n",
    "    #Test\n",
    "    #write_file('test.txt', X_test)\n",
    "    \n",
    "gen_data('/storage/MANZANA/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from collections import Counter\n",
    "print(Counter(data.clase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split into train test sets\n",
    "X_train, X_2, y_train, y_2 = train_test_split(data.image, data.clase, test_size=0.215, random_state=1, stratify=data.clase)\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_test, X_val, y_test, y_val = train_test_split(X_2, y_2, test_size=0.5, random_state=1, stratify=y_2)\n",
    "print(Counter(y_test))\n",
    "print(Counter(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train=pd.DataFrame(data={'image': X_train, 'clase': y_train})\n",
    "train.to_csv(r'/srv/images_classes/Regression/copasVasos_Madrid_LaRioja/train.txt', sep='*', index=None, header=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val=pd.DataFrame(data={'image': X_val, 'clase': y_val})\n",
    "val.to_csv(r'/srv/images_classes/Regression/copasVasos_Madrid_LaRioja/val.txt', sep='*', index=None, header=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test=pd.DataFrame(data={'image': X_test, 'clase': y_test})\n",
    "test.to_csv(r'/srv/images_classes/Regression/copasVasos_Madrid_LaRioja/test.txt', sep='*', index=None, header=None, mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
